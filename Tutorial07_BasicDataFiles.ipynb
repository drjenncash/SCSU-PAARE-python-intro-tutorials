{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f5e2f5",
   "metadata": {},
   "source": [
    "# Tutorial 07: Basic Data Files in Python\n",
    "\n",
    "Sections of this notebook come from several other tutorial notebooks including but not limited to: the Officialy https://docs.python.org/3/tutorial/inputoutput.html, tutorials at the W3 school \n",
    "(https://www.w3schools.com/python/python_ref_file.asp), the Geeks for Geeks website (https://www.geeksforgeeks.org/python/file-handling-python/), Numpy user guide \n",
    "(https://numpy.org/devdocs/user/how-to-io.html). the Krittika Tutorials, and additional sources.\n",
    "\n",
    "This tutorial was compiled for the PAARE project at South Carolina State University in partnership with Clemson University and the University of the Virgin Islands and funded by NSF. (NSF grant AST 2319415)\n",
    "\n",
    "* Originally posted\n",
    "    * JCash June 25, 2025\n",
    "* Last modified:\n",
    "    * JCash July 8, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f195b47",
   "metadata": {},
   "source": [
    "## Overview \n",
    "- File input and output\n",
    "- - Simple text formats\n",
    "  - csv, xls\n",
    "- Accessing data\n",
    "- - Numpy array slices (data-sci/ 1-numpy)\n",
    "  - Pandas dataframe (data-sci/ 4-pandas)\n",
    "\n",
    " \n",
    "In data science, it is very common for your Python code to access a file containing the data you want to analyze. Like most programming languages, there are a variety of techniques available in Python to work with file input and output (I/O for short). \n",
    "\n",
    "Luckily, most astronomical data is saved in formats that are easier to work with once you understand the functions available. In addition to built-in functions for I/O, there are useful functions in both the NumPy and Pandas packages that we will explore in this tutorial. \n",
    "\n",
    "\n",
    "A later tutorial will work with several other common astronomy file formats including fits files. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a2b8d-aa6f-4ee1-bbef-809c27b2883f",
   "metadata": {},
   "source": [
    "### Imports needed\n",
    "\n",
    "* `os` is a package that allow access to the operating system to check paths and files\n",
    "* `numpy` is the standard Numerical Python Package\n",
    "* `pandas` is a standard package that works with data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d484ca0b-a4d7-4a43-a99f-7e694abd3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c820a-5235-4bc5-8728-2cf421470eb6",
   "metadata": {},
   "source": [
    "### Data files needed\n",
    "\n",
    "The data files used in this tutorial are located on GitHub with the tutorials. \n",
    "\n",
    "If you downloaded the entire tutorial repository, the files should be stored in a folder called data in the same directory folder as the tutorials. \n",
    "\n",
    "If you download the tutorials individually, you will need to create a new folder called `data` alongside the tutorials and download/copy the individual files into that data folder. \n",
    "\n",
    "\n",
    "\n",
    "<blockquote> \n",
    "    \n",
    "    **Caution**\n",
    "    \n",
    "    Depending on how you are opening this tutorial or running this code in Python, the kernel will have different rules for how you must specify the pathname for the datafile you are accessing. You may need to change the path definition in the various cells which refer to the data files you should use.\n",
    "    \n",
    "</blockquote>\n",
    "\n",
    "The cell below can check to see if you have the first file we will be using in the expected location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6414c-8fdf-4f80-af0d-fe53c20d54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfilename = './data/the-zen-of-python.txt'\n",
    "\n",
    "if os.path.isfile(testfilename):\n",
    "    print('It finds the file in the expected location')\n",
    "else:\n",
    "    print('The file was not found in the expected location.')\n",
    "    print('Your notebooks working directory is: \\n')\n",
    "    print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa2009-9857-4700-a640-e9035d49fa19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.0) Data file formats\n",
    "\n",
    "Before you can choose the best way to import your data file, you need to know more about the format of that data file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1a4bd-cbc2-4f4d-9905-b30e2fa28fec",
   "metadata": {},
   "source": [
    "### ascii files\n",
    "\n",
    "ASCII files are generic format files that can be read or produced by most applications. There are three common ASCII data formats: .DAT, .CSV, and .TXT. ASCII files are generic format files read or produced by most applications. These files can also be imported into most applications, including word processors, spreadsheets, and ASCII editors.\n",
    "\n",
    "Ascii files can be viewed by text editors and web browsers very easily. You will want to visually look at the file contents (at least the first few lines) to understand the data better. \n",
    "\n",
    "Things to look for:\n",
    "* Can I view the text?\n",
    "* Is there a common format on each line of the file?\n",
    "* What separates one piece of information from the next (space, comma, tab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cf52e-4972-4850-9b01-8e34017af740",
   "metadata": {},
   "source": [
    "### Spreadsheet files\n",
    "\n",
    "Add more info here...\n",
    "\n",
    ".xls and .ods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e59ac-9482-4184-95fd-ad0cd7ccf42f",
   "metadata": {},
   "source": [
    "### Other data formats\n",
    "\n",
    "In this tutorial, we note that there are many other file formats that can be used for storing data. A complete coverage of these files is beyond the scope of this tutorial. Another later tutorial in this series does cover a common astronomical data file type called a .fits file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc689c23-ab3d-4969-8fee-730b97bedaec",
   "metadata": {},
   "source": [
    "### Data Examples\n",
    "\n",
    "Throughout this tutorial, we will show specific examples of opening Data files with the various techniques. For these tutorials, all data files will be contained in a directory `data/` stored alongside the tutorial files. You will need to ensure these data files are downloaded/uploaded with the Jupyter notebooks. \n",
    "\n",
    "If you are working on a jupyter-notebook server such as Anaconda on the Cloud or the Rubin Science Platform, you should be able to view the data files in the jupyter-server. \n",
    "\n",
    "When we say `filename`, that is a string which contains both the path to the file and the name of the file. \n",
    "\n",
    "If you download the entire tutorial directory with the `data/` directory, you can reference individual files with the syntax `./data/filename`\n",
    "For example the first file we will look at is the file named \"the-zen-of-python.txt\". In that case the full filename with path would be written as \n",
    "`\"./data/the-zen-of-python.txt\"`\n",
    "\n",
    "\n",
    "<blockquote> \n",
    "    \n",
    "    **Caution**\n",
    "    \n",
    "    Depending on how you are opening this tutorial or running this code in Python, the kernel will have different rules for how you must specify the pathname for the datafile you are accessing. You may need to change the path definition in the various cells which refer to the data files you should use.\n",
    "    \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21344588-3146-461c-97e8-39da144165b1",
   "metadata": {},
   "source": [
    "## 2.0)  Unformatted text files\n",
    "\n",
    "If a file contains ascii text but there is no standard format line by line, then you will probable need to read each line of the file into string variables. \n",
    "\n",
    "Depending on what you need from the file, you may use a variety of string functions and conditional statements to extract that information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10665d-d1c5-48f0-9081-619e92d3ce64",
   "metadata": {},
   "source": [
    "### 2.1) Built-in open function\n",
    "\n",
    "Within Python, one of the built-in functions is `open()`.\n",
    "\n",
    "\n",
    "- A typical call will be of the form\n",
    "    - `file = open(filename)`\n",
    "- The parameter you pass in this function is `filename` which should be a string variable\n",
    "- Optionally you can specify the mode\n",
    "    - The default if you do not specify the mode is 'r' for read access\n",
    "    - Other common options are: 'w' to write to a file and 'a' to append to an existing file\n",
    "- The output is a file object (not the contents of the file)\n",
    "    - You still need to use other functions to read or write to that file\n",
    " \n",
    "The **file object** is a Python class with a variety of methods available. \n",
    "We will look at several of these to help you understand the options.\n",
    "\n",
    "As we move forward, we will use shorter versions of these calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af85951-f0f3-4f2e-811b-9a280a6d903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the line below by removing the # symbol to see the full help information on this function.\n",
    "#help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc21c78-a76c-455f-813d-76540710593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the filename. \n",
    "filename = \"./data/the-zen-of-python.txt\"\n",
    "\n",
    "print(type(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5e98d-b79b-4983-a301-ad2a1df366e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a file to create a file object.\n",
    "fileobj = open(\"./data/the-zen-of-python.txt\",'r')\n",
    "print(type(fileobj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400920c4-94d8-4466-9e4b-10a0f9eb50bc",
   "metadata": {},
   "source": [
    "#### Checking a file\n",
    "\n",
    "When you first work with a data file, you may need to check to see if it is readable before moving forward. \n",
    "\n",
    "In general, you will already know what type of file you have and can skip this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067d77b-6038-4766-bde9-a540ebe5fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing is a file is readable.\n",
    "print(fileobj.readable())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599fa70-3057-4229-bc44-5ae304028251",
   "metadata": {},
   "source": [
    "#### Reading the full file\n",
    "\n",
    "You can read in the full file into one big string using the `.read()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c87a1-d830-4c3b-9932-0c52f62a4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileobj = open(filename)\n",
    "result = fileobj.read()\n",
    "print(type(result))\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d932fc-9673-4f1f-93c2-cdc6413fb5c1",
   "metadata": {},
   "source": [
    "#### Reading in the file line by line\n",
    "\n",
    "The `readlines()` method will give you a list where each item in the list is a string containing one line of the file.\n",
    "\n",
    "You can then do things with each line of the file by indexing the list and using string operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d2707-0565-4931-b1b7-b058d786c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileobj = open(filename)\n",
    "lines = fileobj.readlines()\n",
    "\n",
    "print(type(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ce0fe-1104-4334-9f43-3d14a3a3405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows the number of lines in the file.\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48cc3a-72d8-4aa1-85e3-ac18472078bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Printing out a single line by indexing.\n",
    "print(lines[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741715ee-f960-4abf-8ec4-1e7b62d08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print a subsection of the lines.\n",
    "print(lines[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a95c6-7929-41ec-8960-3ee444a044f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over the list of lines to test for a substring.\n",
    "for line in lines:\n",
    "    if \"by\" in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b3ba6-4385-4735-940a-3b33a445a036",
   "metadata": {},
   "source": [
    "#### Splitting the lines into words\n",
    "\n",
    "If you needed to separate each line of the file into individual words, we can then use string splitting on the list of lines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311bad1-6ab1-43c6-bc4e-401227a39bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileobj = open(filename)          #open the fileobject\n",
    "lines = fileobj.readlines()       #read the lines into a list of lines\n",
    "words = []                        #create an empty list to hold the words\n",
    "for line in lines:                #go line by line\n",
    "    words.append(line.split(' ')) # split each line at the spaces\n",
    "\n",
    "print(words[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093888c0-80f4-476e-a7de-e5dba27da273",
   "metadata": {},
   "source": [
    "#### Closing a file\n",
    "\n",
    "Notice that in the above examples, we had to open the file each time. Technically, we should be closing the file in between these open calls. This frees up the memory that was being held by the fileobject\n",
    "\n",
    "Two methods exist in python:\n",
    "* `.closed()` checks to see if the fileobj is open or closed and return a True or False Boolean value\n",
    "* `.close()`  closes an open fileobj\n",
    "\n",
    "Execute the three cells below to \n",
    "1) check the status (should get that it is still open)\n",
    "2) close the file\n",
    "3) check the status (should now get that it is closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89650f-3a4d-4c10-9eb6-ef7945674b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if a fileoject is closed\n",
    "if fileobj.closed == True:\n",
    "    print('it is closed')\n",
    "elif fileobj.closed == False:\n",
    "    print('it is still open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aeff46-7047-4b97-824c-112f07b51f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the syntax to close a file\n",
    "fileobj = open(filename)\n",
    "lines = fileobj.readlines()\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442680a6-5d83-4eac-81b0-a866b8c30dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if a fileoject is closed now\n",
    "if fileobj.closed == True:\n",
    "    print('it is closed')\n",
    "elif fileobj.closed == False:\n",
    "    print('it is still open')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e5a7c-1a9e-4383-9d0f-a749051da877",
   "metadata": {},
   "source": [
    "**with statements to open a file**\n",
    "\n",
    "Using a `with` statement allows python to open the file, execute a section of code and then properly close the `fileobject` without having to do an explicit `close` command. For this reason, it is often the preferred method. \n",
    "\n",
    "The syntax is a little different for the order of the command but it contains the same information in a more compact format.\n",
    "\n",
    "Since the variable for the fileobject is only used inside the with statement, it is often shortened to just `f` (just make sure you have not already used that variable name for something else).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259ec68-79fa-4585-b8eb-f2f1e7131734",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/the-zen-of-python.txt\"\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    words =[]\n",
    "    for line in lines:\n",
    "        words.append(line.split(' '))\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748adab2-0bc6-47f4-83c0-7f1566f112ff",
   "metadata": {},
   "source": [
    "### 2.2) Advantages of the open function\n",
    "\n",
    "The advantage of using the built-in `open()` function in Python is that it will work for any ascii textfile. \n",
    "\n",
    "- The file can contain any number of rows of any length. \n",
    "- The length of each line doesn't matter.\n",
    "- The lines can contain any type of information\n",
    "- You can treat each line anyway you need to in order to extract any information you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80499a-43b2-4e09-b4d6-676aaec11875",
   "metadata": {},
   "source": [
    "### 2.3) DisAdvantages of the open function\n",
    "\n",
    "Although the `open()` function is very powerful, there are often more efficient ways to access the data in the file **IF** it has a well ordered structure for the data. \n",
    "\n",
    "You do need to know your data first to use these other methods but once you do, you can use the best method from the other ones in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597e065-d137-4001-8bc8-e658c6237338",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3.0) Column formatted text files \n",
    "\n",
    "If the data file contains ascii text with a standard format on each line, we have some more efficient ways to read in and work with the data.\n",
    "\n",
    "In particular, in Data Science we often have columns of data with each row containing the same number of columns. \n",
    "\n",
    "Below are examples of a few files that we will now be using. We summarize the first few lines of each files as raw text here just to give you a view of each file. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "35e20a55-b4e4-418e-86e7-e2a8a55459b4",
   "metadata": {},
   "source": [
    "#The file \"syn.txt\"\n",
    "\n",
    "0.048962338191566035 12.070034199388704\n",
    "0.47187691702469947 12.64081926075754\n",
    "0.6640550445890903 12.855809193661562\n",
    "0.8374849760923397 13.012717783375788\n",
    "1.2259257577901583 13.207036063138272\n",
    "\n",
    "\n",
    "#The file \"GCN25560.txt\"\n",
    "\n",
    "    JD           dt_minutes   ap_mag   Mag_err\n",
    "2458725.366  51.16  16.93   0.01\n",
    "2458725.372  59.80  17.21   0.02\n",
    "2458725.394  91.48  18.00   0.12\n",
    "2458725.400 100.12  18.08   0.04\n",
    "\n",
    "\n",
    "\n",
    "#The file \"galaxies.txt\"\n",
    "\n",
    "# mangaid,objra,objdec,redshift\n",
    "1,133.3711,57.598427,0.039515216\n",
    "2,133.68567,57.48025,0.041055806\n",
    "3,136.01717,57.09233,0.04657103\n",
    "4,133.98996,57.677967,0.01435065\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The file \"Moons_and_planets.csv\"\n",
    "\n",
    "# Name of Moon, Name of Planet, Diameter (km)\n",
    "Moon,Earth,1737.1\n",
    "Phobos,Mars,11.1\n",
    "Deimos,Mars,6.2\n",
    "Io,Jupiter,1818.1\n",
    "Europa,Jupiter,1560.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0917d-78c8-47a1-ae9e-21d7a8e0ee99",
   "metadata": {},
   "source": [
    "We could use the open file method described in the previous section. \n",
    "\n",
    "It will read in the lines and put the strings into a list. \n",
    "\n",
    "To use the values as numbers, we would still need to: \n",
    "- Strip off the next line character,\n",
    "- Split the lines into strings,\n",
    "- Convert each string into a number.\n",
    "\n",
    "This works as shown below (without a detailed explanation of each step), but takes a lot of code to do everything we need.\n",
    "\n",
    "> **Note** This is not the recommended method to read in a data file like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbead6-4e14-4b73-82a1-54637fc47b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/syn.txt\" \n",
    "with open(filename) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data =[]\n",
    "for line in lines:\n",
    "    temp = line.rstrip('\\n')\n",
    "    vals = temp.split(' ')\n",
    "    values = []\n",
    "    for val in vals:\n",
    "        values.append(float(val))\n",
    "    data.append(values)\n",
    "    \n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21d8f8-270c-4363-91c5-525ca3c00196",
   "metadata": {},
   "source": [
    "### 3.1) Numpy loadtxt\n",
    "\n",
    "**If** the data file contains ascii text  of numbers organized into columns of data...\n",
    "\n",
    "One more efficient method you can use is the numpy function `np.loadtxt`.\n",
    "\n",
    "The general syntax is `data = np.loadtxt(filename, delimiter = None, skiprows = 0)`. \n",
    "\n",
    "If you do not specify a delimiter, it will assume whitespace.\n",
    "\n",
    "If you do not specify a number of rows to skip at the start of the file, it will start with the first line.\n",
    "\n",
    "Full documentation is given at:\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771436f-0824-43b5-bd73-446d5779e321",
   "metadata": {},
   "source": [
    "#### Files with just numbers and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59857e00-1b81-4d60-9556-a087264b3524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04896234, 12.0700342 ],\n",
       "       [ 0.47187692, 12.64081926],\n",
       "       [ 0.66405504, 12.85580919]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is the code to read in the syn.txt file. \n",
    "filename = \"./data/syn.txt\"     #Set the path to the file.\n",
    "data = np.loadtxt(filename)     #Read in the file contents to a numpy array, no special options needed.\n",
    "\n",
    "# Here we can view the first tthree rows to make sure that it is reading in the data as expected\n",
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26064273-ddf0-4710-b036-0985b065fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Length: 500\n",
      "Dimensions: 2\n",
      "Shape: (500, 2)\n",
      "Type of individual value: <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Here we can examine information about the data.\n",
    "print('Type:',type(data))\n",
    "print('Length:',len(data))\n",
    "print('Dimensions:',data.ndim)\n",
    "print('Shape:',np.shape(data))\n",
    "print('Type of individual value:',type(data[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41479900-0685-4638-b3a4-3dfdc191a6c2",
   "metadata": {},
   "source": [
    "As you can see above, the data is immediately accessible as a NumPy 2D data array with just a single line of code to readin the data from the file and format it as numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c25481-1461-44f1-9d0f-cd66ee008bda",
   "metadata": {},
   "source": [
    "#### Files with a header\n",
    "\n",
    "A header is a line or lines at the top of the data file containing information about the data. This information is very useful in understanding the data, but we need to be careful in how we read in the file. \n",
    "\n",
    "For `np.loadtxt` you can skip reading in these rows using the `skiprows=` parameter. \n",
    "- The default value is None\n",
    "- Otherwise, it should be an integer equal to the number of lines to skip before reading the data.\n",
    "- lines which start with the `#` symbol are considered comments and skipped automatically, but can use a skiprows parameter\n",
    "\n",
    "For our example files, \n",
    "- syn.txt had no header\n",
    "- GCN25560.txt has a single line header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b083bd2-9515-4e25-b019-82dced568b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example that skips the header line.\n",
    "filename = './data/GCN25560.txt'\n",
    "data = np.loadtxt(filename,skiprows=1)\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203b51f-14fc-4861-8aff-4331570e0ee4",
   "metadata": {},
   "source": [
    "#### Files that are comma separated\n",
    "\n",
    "By default, the `np.loadtxt` assumes that the separator between the data columns in a whitespace. \n",
    "If a data file has commas seperating the values in the columns, we can still use the same method but we have to specify the delimiter.\n",
    "\n",
    "These comma-separated-values files are often given the extension of `.csv` but can also have `.txt` or `.dat` extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecfa16a-0c17-418c-bc16-b75cf366707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.3337110e+02, 5.7598427e+01, 3.9515216e-02],\n",
       "       [2.0000000e+00, 1.3368567e+02, 5.7480250e+01, 4.1055806e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is a comma delimited example with one header row.\n",
    "filename = './data/galaxies.txt'\n",
    "data = np.loadtxt(filename, delimiter =',', skiprows =1)\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231cbed-42d4-4c1d-a182-1f5c1e93c2c3",
   "metadata": {},
   "source": [
    "#### Getting Numpy column data to work with\n",
    "\n",
    "If you read your data into a numpy 2D array, then you can access a data column using index slicing.\n",
    "\n",
    "In general, `data[:,i]` will grab all rows for the i index column and return a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c946c15-03fd-42f7-90f2-9d5bdc3f0e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 1\n",
      "Shape of the column array: (4656,)\n",
      "Type of column array: <class 'numpy.ndarray'>\n",
      "First few values of col0 [1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# This grabs all rows from the column with index 0 and assigns it to the variable col0\n",
    "col0 = data[:,0]\n",
    "\n",
    "# We can examine that variable to better understand the shape and format\n",
    "print('Dimensions:',col0.ndim)\n",
    "print('Shape of the column array:',col0.shape)\n",
    "print('Type of column array:',type(col0))\n",
    "print('First few values of col0', col0[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1428b7ad-b709-4275-b710-1e32569cf30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 1\n",
      "Shape of the column array: (4656,)\n",
      "Type of flattened array: <class 'numpy.ndarray'>\n",
      "First few values of col0 [0.03951522 0.04105581]\n"
     ]
    }
   ],
   "source": [
    "# This syntax grabs the index 3 column and creates a 1D array\n",
    "arr3 = data[:,3]\n",
    "\n",
    "# We can examine that variable to better understand the shape and format\n",
    "print('Dimensions:',col0.ndim)\n",
    "print('Shape of the column array:',arr3.shape)\n",
    "print('Type of flattened array:',type(arr3))\n",
    "print('First few values of col0', arr3[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa12ad-21d3-4b22-9e1f-d6b391d1268e",
   "metadata": {},
   "source": [
    "### 3.2) Using Numpy if data are not all numbers\n",
    "\n",
    "NumPy is most efficient when working with numbers. Further a numpy array must have only one data type. By default, `np.loadtxt` assumes that the data can all be converted to float values. \n",
    "\n",
    "If even one value in the data file is a non numeric string, `np.loadtxt` will give an error when it tries to convert that string into a float value. \n",
    "\n",
    "We can work around this by specifically telling numpy to use a string data type when working with the file. \n",
    "\n",
    "Below, are examples of using `np.loadtxt` with the Moons_and planets.csv file\n",
    "- The first shows the correct syntax to use to get strings\n",
    "- The second cell shows the error statement you will get without the data type\n",
    "    - uncomment the command and execute to see the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12e40d-d323-4e41-9acb-8d4e6562e44d",
   "metadata": {},
   "source": [
    "---\n",
    "**Correct method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99341806-f1cb-49cf-844e-c7159637442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the correct call\n",
    "file = \"./data/Moons_and_planets.csv\"\n",
    "data2 = np.loadtxt(file,dtype=\"str\",delimiter=',',skiprows=1)\n",
    "\n",
    "print(type(data2))\n",
    "data2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd4009-4c59-45dd-828d-b2289549106b",
   "metadata": {},
   "source": [
    "---\n",
    "**Incorrect method**\n",
    "\n",
    "Which will give an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec824fe6-a611-4e2b-9220-84057d94489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./data/Moons_and_planets.csv\"\n",
    "#This will give a ValueError\n",
    "\n",
    "#Uncomment the line below to see what the error looks like\n",
    "#data2 = np.loadtxt(file,delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a5b22-f6c2-4eba-b631-c41022a4b437",
   "metadata": {},
   "source": [
    "Now the numpy array is an array of string values, both the words and numbers are left as strings.\n",
    "\n",
    "\n",
    "Additional information on using Numpy including a few additional functions and formats can be found at:\n",
    "\n",
    "https://numpy.org/doc/stable/user/how-to-io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a7fc2-4dfb-43ca-98b2-67f8bcbe24e0",
   "metadata": {},
   "source": [
    "### 3.3) Reading in files with Pandas\n",
    "\n",
    "Since data files may have mixed data types, numpy is not the right choice for all data files. Several other packages focus on different ways to work with Data files. **Pandas** is a very commonly used one. \n",
    "\n",
    "In their documentation they use the description: \n",
    "\n",
    "pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. Full documentation and Users guides can be found at https://pandas.pydata.org/docs/\n",
    "\n",
    "Advantages of pandas\n",
    "- It deals with multiple data types easily\n",
    "- The resulting data structure for numeric columns can be easily converted to numpy arrays\n",
    "- There are functions and methods to work with the data in the table\n",
    "- Any header information can be used to define column names (instead of just skipping the lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df814701-d2eb-49c1-a488-b45545505f08",
   "metadata": {},
   "source": [
    "#### Pandas read csv\n",
    "\n",
    "When working with data files with comma seperated values, you can use the `pd.read_csv()` function. \n",
    "\n",
    "The required parameter is the string filename, and the output is a pandas dataframe object.\n",
    "\n",
    "It is common to use df in the output variable name to indicate that it is a DataFrame, but this is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1beccd45-e193-4c1e-bf9a-ce1c8ae9e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading in the datafile\n",
    "filename = './data/galaxies.csv'\n",
    "gal_df = pd.read_csv(filename)\n",
    "\n",
    "type(gal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4dca5-a965-483d-978d-6e0589cd32f8",
   "metadata": {},
   "source": [
    "#### Viewing the Dataframe\n",
    "We can use the same format to examine the first few lines of the data as we did with the NumPy arrays, but we immediately see that the output is easier to read. \n",
    "\n",
    "The column names were taken from the header automatically, and the values are shown in the normal decimal place format instead of the scientific notation format we saw in the numpy arrays. \n",
    "\n",
    "When you view an entire dataframe that is large, you will get a truncated view with the first 5 rows, and line of `...` and then the last five rows. At the end it shows the shape of the data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73511425-dee7-4235-a8ab-aa9ace3fda89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mangaid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133.37110</td>\n",
       "      <td>57.598427</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>133.68567</td>\n",
       "      <td>57.480250</td>\n",
       "      <td>0.041056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>136.01717</td>\n",
       "      <td>57.092330</td>\n",
       "      <td>0.046571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>133.98996</td>\n",
       "      <td>57.677967</td>\n",
       "      <td>0.014351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>136.75137</td>\n",
       "      <td>57.451435</td>\n",
       "      <td>0.046406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>4652</td>\n",
       "      <td>228.41486</td>\n",
       "      <td>28.244461</td>\n",
       "      <td>0.046080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>4653</td>\n",
       "      <td>226.99060</td>\n",
       "      <td>28.881860</td>\n",
       "      <td>0.058178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>4654</td>\n",
       "      <td>228.07332</td>\n",
       "      <td>29.657210</td>\n",
       "      <td>0.069022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>4655</td>\n",
       "      <td>227.04141</td>\n",
       "      <td>29.222193</td>\n",
       "      <td>0.111297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>4656</td>\n",
       "      <td>228.17638</td>\n",
       "      <td>27.799559</td>\n",
       "      <td>0.068651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4656 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mangaid      objra     objdec  redshift\n",
       "0             1  133.37110  57.598427  0.039515\n",
       "1             2  133.68567  57.480250  0.041056\n",
       "2             3  136.01717  57.092330  0.046571\n",
       "3             4  133.98996  57.677967  0.014351\n",
       "4             5  136.75137  57.451435  0.046406\n",
       "...         ...        ...        ...       ...\n",
       "4651       4652  228.41486  28.244461  0.046080\n",
       "4652       4653  226.99060  28.881860  0.058178\n",
       "4653       4654  228.07332  29.657210  0.069022\n",
       "4654       4655  227.04141  29.222193  0.111297\n",
       "4655       4656  228.17638  27.799559  0.068651\n",
       "\n",
       "[4656 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe as a whole\n",
    "gal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7490865-6966-4aad-87ce-b2be02b9ea5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mangaid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133.37110</td>\n",
       "      <td>57.598427</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>133.68567</td>\n",
       "      <td>57.480250</td>\n",
       "      <td>0.041056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>136.01717</td>\n",
       "      <td>57.092330</td>\n",
       "      <td>0.046571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mangaid      objra     objdec  redshift\n",
       "0          1  133.37110  57.598427  0.039515\n",
       "1          2  133.68567  57.480250  0.041056\n",
       "2          3  136.01717  57.092330  0.046571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can show specific lines with their index range\n",
    "\n",
    "#index 0 up to 3\n",
    "gal_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9238799d-cbf9-461d-b721-e07ef6a2c491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mangaid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>317.04016</td>\n",
       "      <td>-0.250806</td>\n",
       "      <td>0.095097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152</td>\n",
       "      <td>316.97476</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>0.058050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153</td>\n",
       "      <td>317.31490</td>\n",
       "      <td>0.523469</td>\n",
       "      <td>0.050923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>154</td>\n",
       "      <td>322.94946</td>\n",
       "      <td>-1.039170</td>\n",
       "      <td>0.051821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155</td>\n",
       "      <td>322.92880</td>\n",
       "      <td>0.357835</td>\n",
       "      <td>0.030129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>324.09200</td>\n",
       "      <td>0.947727</td>\n",
       "      <td>0.103859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     # mangaid      objra    objdec  redshift\n",
       "150        151  317.04016 -0.250806  0.095097\n",
       "151        152  316.97476  0.875871  0.058050\n",
       "152        153  317.31490  0.523469  0.050923\n",
       "153        154  322.94946 -1.039170  0.051821\n",
       "154        155  322.92880  0.357835  0.030129\n",
       "155        156  324.09200  0.947727  0.103859"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can show specific lines with their index range\n",
    "\n",
    "#index 150 up to 156\n",
    "gal_df[150:156]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfa906-d1a9-41ed-88da-f719494b9fd2",
   "metadata": {},
   "source": [
    "#### Getting Pandas column data to work with\n",
    "\n",
    "If you read your data file into a Pandas dataframe, you can extract out a single column using the keywords in the header. \n",
    "\n",
    "If you aren't sure what the keywords are, you can use the  `df.columns` method as shown below. You will get a list of the strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b717a391-3d63-44b2-825b-4e2ce6c251cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# mangaid', 'objra', 'objdec', 'redshift'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the columns in the gal_df datafram\n",
    "gal_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17dcdc-20cf-4a54-8e62-a56dda94207b",
   "metadata": {},
   "source": [
    "To get just one column you will use the format `df['name']` which will return an object which is a Pandas Series. \n",
    "\n",
    "In most situations, this Series can be used as if it was a NumPy array. \n",
    "\n",
    "The example below, shows the extraction of the redshift column and then the numpy function to return the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9b1ae92-bdf8-4d05-826e-49484dc06407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column is the type: <class 'pandas.core.series.Series'>\n",
      "The column has a length of: 4656\n",
      "The maximum value is: 0.27818364\n"
     ]
    }
   ],
   "source": [
    "# This extracts the redshift column and assigns it to the variable name reds\n",
    "reds = gal_df['redshift']\n",
    "\n",
    "# Here we get some info on that extracted column\n",
    "print('The column is the type:',type(reds))\n",
    "print('The column has a length of:', len(reds))\n",
    "\n",
    "# We can do math on the column\n",
    "print('The maximum value is:',np.max(reds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337b392-247f-427e-8c3c-7cd0b4e9ff45",
   "metadata": {},
   "source": [
    "#### Pandas with other column data files\n",
    "\n",
    "We can use the `pd.read_csv()` function even if the data has a different separator.\n",
    "\n",
    "You will need to specify the `delimiter` keyword or the equivalent `sep` keyword (short for separator)\n",
    "\n",
    "- A single space delimiter will use `sep=' '`\n",
    "- A variable number of white spaces will use `sep='\\s+'`\n",
    "- A comma would use `sep=','` if you leave off sep, the comma will be assumed\n",
    "\n",
    "If you don't have a header line on the file, you can use the `header=None` keyword. In that case, the column names will be the index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "652148b3-b402-496a-8a03-2a9cd1a200ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JD</th>\n",
       "      <th>dt_minutes</th>\n",
       "      <th>ap_mag</th>\n",
       "      <th>Mag_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2458725.366</td>\n",
       "      <td>51.16</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2458725.372</td>\n",
       "      <td>59.80</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            JD  dt_minutes  ap_mag  Mag_err\n",
       "0  2458725.366       51.16   16.93     0.01\n",
       "1  2458725.372       59.80   17.21     0.02"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the syn.txt file\n",
    "filename = './data/GCN25560.txt'\n",
    "df1 = pd.read_csv(filename,sep='\\s+')\n",
    "\n",
    "df1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc628016-2199-4db9-ba8b-49202a49f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      " Index([0, 1], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048962</td>\n",
       "      <td>12.070034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471877</td>\n",
       "      <td>12.640819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1\n",
       "0  0.048962  12.070034\n",
       "1  0.471877  12.640819"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the syn.txt file\n",
    "#Here we set the delimiter and also say no header\n",
    "filename = './data/syn.txt'\n",
    "df2 = pd.read_csv(filename, sep=' ', header=None)\n",
    "\n",
    "print('Column names:\\n',df2.columns)\n",
    "\n",
    "df2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f7af5-3257-4872-8970-890743bf91e6",
   "metadata": {},
   "source": [
    "#### Pandas with mixed data types\n",
    "\n",
    "While the Moons_and_planets data file was very hard to deal with using numpy, pandas has no difficulty with it at all. \n",
    "\n",
    "We can examine the dataframe to see the datatypes for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d07cfbb-6663-4b2a-9a04-5c9c9371433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Name of Moon</th>\n",
       "      <th>Name of Planet</th>\n",
       "      <th>Diameter (km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moon</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1737.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phobos</td>\n",
       "      <td>Mars</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Name of Moon  Name of Planet   Diameter (km)\n",
       "0           Moon           Earth          1737.1\n",
       "1         Phobos            Mars            11.1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we see that it easily handles text and numbers\n",
    "filename = \"./data/Moons_and_planets.csv\"\n",
    "df3 = pd.read_csv(filename)\n",
    "\n",
    "df3[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72e60466-e816-4826-8bb0-360498ce4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['# Name of Moon', ' Name of Planet', ' Diameter (km)'], dtype='object')\n",
      "DataTypes for each column:\n",
      " # Name of Moon      object\n",
      " Name of Planet     object\n",
      " Diameter (km)     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Column names:',df3.columns)\n",
    "print('DataTypes for each column:\\n',df3.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29858c88-d47c-4d45-a683-66678826b269",
   "metadata": {},
   "source": [
    "## 4.0) Working with spreadsheet files\n",
    "\n",
    "While text and csv files are ascii files where the data is stored in a way that you can directly view the file, Spreadsheet programs such as Microsoft Excel or LibreOffice Calc, create files that are not ASCII. \n",
    "\n",
    "To read in the data files, we need to use different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97b7a3-a974-47fd-9ddf-9b782a479c2c",
   "metadata": {},
   "source": [
    "### 4.1) convert to csv\n",
    "\n",
    "If you only need to work with one spreadsheet file, it may be easier to open that spreadsheet with spreadsheet software and use the `Save As` options to save it out as a .csv file. Then you can use the methods described above to bring in the new .csv file into python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5be52-7046-4969-9dc0-393971028b17",
   "metadata": {},
   "source": [
    "### 4.2) Pandas and Excel\n",
    "\n",
    "Excel is commonly used enough that Pandas has a method to work with the Excel files using `pd.read_excel()` instead of `pd.read_csv()`.\n",
    "\n",
    "The function call is very similar to the `read_csv` if you only have a single sheet in the spreadsheet file. \n",
    "\n",
    "If you have multiple sheets or only need to pull in a specific range of cells from the spreadsheet, there are keyword parameters to do this. \n",
    "\n",
    "We show only the simple example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22190bd3-b3c3-4982-a75f-e2e8f99d529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/galaxies.xlsx'\n",
    "\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a8185-75fb-4027-9626-76297dedcd9a",
   "metadata": {},
   "source": [
    "## 5.0) Writing Output files\n",
    "\n",
    "**not finished**\n",
    "\n",
    "Need \n",
    "* writing out numpy 1D as a column\n",
    "* writing multiple 1D as columns\n",
    "* writing out 2D as rows and columns\n",
    "* adding header\n",
    "* delimitors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd2e6d-7057-4bf6-af77-06dc6a993040",
   "metadata": {},
   "source": [
    "### Simple ASCII text files of numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b051b-800c-4f1f-af2d-abd6380bacb6",
   "metadata": {},
   "source": [
    "SImilar in nature to the `np.loadtxt()` fucntion, we have a `np.savetxt()` function.\n",
    "\n",
    "The basic syntax is `np.savetxt(fname,X)`\n",
    "* fname is a string for the filename with path\n",
    "* X is a 1D or 2D numpy array\n",
    "\n",
    "Additional optional keyword arguments are:\n",
    "* delimiter = ' '  which is a string or character separating columns\n",
    "* header = ''  a string that will be written at the beginning of the file\n",
    "* footer ='' which is a string that will be written at the end of the file\n",
    "\n",
    "There are several additional options  that are not covered in this tutorial, but full documentation can be found at:\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html#numpy.savetxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16120bb5-8740-4546-8a8b-6fdddaf7e54c",
   "metadata": {},
   "source": [
    "--- \n",
    "**Examples**\n",
    "\n",
    "Each of these examples will use the same data and create a new output file. Once you run the code you can view the output files to see the effects of each choice. If you rerun the code, it will overwrite any previous version of that output file. \n",
    "\n",
    "Notice that the various files also use the np.stack functions to deal with mutliple arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c395b-7df5-4be9-907d-f174eaf02f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up some arrays to test writing out data\n",
    "x = np.arange(50)\n",
    "y = x**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50f3810-9e25-49db-b9b3-56f01d1351d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x values listed as a column\n",
    "np.savetxt('out1.txt',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b048b77-ee06-472a-ace2-48b4baa35f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x values listed as a column with some formatting\n",
    "np.savetxt('out2.txt',x,fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712557e-5e1c-4f4f-aa0b-2cc62901245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x and y values listed as individual rows with space delimiters.\n",
    "np.savetxt('out3.txt',np.stack([x,y],axis=0),fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353c5ba-36f8-4c6f-a8a2-b3a58e212791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x and y values listed as individual columns with space delimiters.\n",
    "np.savetxt('out4.txt',np.stack([x,y],axis=1),fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681f694-160d-41c4-acc7-b8dfa654b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x and y values listed as individual columns with comma delimiters.\n",
    "np.savetxt('out5.txt',np.stack([x,y],axis=1),delimiter=',',fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a3966-2ba9-4bf3-b66c-9cf8547a94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x and y values listed as individual columns with comma delimiters.\n",
    "#A header line is added as well\n",
    "np.savetxt('out6.txt',np.stack([x,y],axis=1),delimiter=',',header = 'x,y',fmt='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcdcf4-f700-4c57-9093-7ffcf69b8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a file with the x and y values listed as individual columns with tab delimiters.\n",
    "#A header line is added as well\n",
    "np.savetxt('out7.txt',np.stack([x,y],axis=1),delimiter='\\t',header = '   x \\t y',fmt='%5.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af82ca-f05d-431f-8c22-1f109145580a",
   "metadata": {},
   "source": [
    "### Simple csv file from pandas\n",
    "\n",
    "The previous section looked at writing out data from numpy arrays. If your data is in a pandas dataframe, then you can write out the data to a csv file using methods from the pandas library. \n",
    "\n",
    "To continue with one of our previous examples, we used pandas to read in the `syn.txt` data file. We can now write that file out as a `.csv` file.\n",
    "\n",
    "Since it is a method it is called on the dataframe object with the general format of:\n",
    "`mydf.to_csv(filename)`\n",
    "\n",
    "You can use additional optional keyword arguments to adjust the formatting of the data in the file. \n",
    "Full documentation can be found at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "\n",
    "In the code cell below, we first read in the `.txt` data file and then write it out to a new filename as a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da7c8-6aa2-4b72-be34-aef5bdac8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the syn.txt file\n",
    "#Here we set the delimiter and also say no header\n",
    "filename = './data/syn.txt'\n",
    "syndf = pd.read_csv(filename, sep=' ', header=None)\n",
    "\n",
    "#Here we write out the file with a header and not including the column of row index\n",
    "syndf.to_csv('./data/syn.csv',header = ['time','flux'], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29f4b6-ea4e-46f7-b860-26ff3bc25998",
   "metadata": {},
   "source": [
    "# Assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b866aff-404a-4c81-910b-655d14fe79f2",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise, you will be working with the file 'NGC5272.txt'\n",
    "\n",
    "---\n",
    "**Instructions**\n",
    "\n",
    "1) Use the built-in open method to read in the lines of the file\n",
    "    - Don't forget to close the file when done\n",
    "2) Print the first three lines of the file\n",
    "   - Use this to determine if the file has a header line\n",
    "   - Use this to determine what delimiter is used\n",
    "3) Using numpy, read in the data\n",
    "    - Print out the number of data rows\n",
    "    - Print out the first five rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1db295-15e8-4f5c-9370-c852b379430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: use open and readlines to get the data\n",
    "\n",
    "\n",
    "# Step 2: print out the first three lines\n",
    "\n",
    "\n",
    "# Step 3: use numpy to read the data\n",
    "\n",
    "\n",
    "# Step 3b: print out the number of rows of data\n",
    "\n",
    "\n",
    "# Step 3c: print out the first five rows of data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62952e88-f8fe-48ca-a8b8-1899b88c4df4",
   "metadata": {},
   "source": [
    "## Exercise 2  \n",
    "\n",
    "This exercise continues with the same data file `NGC5272.txt` you worked with in the last exercise. \n",
    "\n",
    "---\n",
    "**Instructions**\n",
    "\n",
    "1) Use Pandas to read the data into a dataframe\n",
    "2) Show the top 5 rows of the dataframe\n",
    "3) Write out the dataframe to a `.csv` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6bc8b-3973-47ea-889f-c06ddc166ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your code (feel free to separate your code into multiple cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca958f-7b27-4046-8946-79fca3811316",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "To practice reading and writing data files, complete this exercise using the syn.txt datafile. You will practice both the numpy and pandas ways to read in the data and get specific columns to work with. \n",
    "\n",
    "---\n",
    "**Instructions**\n",
    "\n",
    "1) Use np.loadtxt to read in the `syn.txt` file\n",
    "2) Print out the dimensions of the data\n",
    "3) Assign the first column to the variable name x and the second to the variable name y\n",
    "\n",
    "\n",
    "4) Now use Pandas to read in the `syn.txt` file\n",
    "5) Print out the dimensions of the data\n",
    "6) Assign the first column to the variable name x and the second to the variable name y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a246859-e25d-470c-815c-22bb39df3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here for 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd76f35a-34a1-4169-990d-92076734160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here for 4-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e7c5e-7002-4c4f-96ea-64125d432acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
