{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b64be04-b60e-424d-b3c4-c49cd869ba54",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TBA:</b> jcash will improve text here\n",
    "\n",
    "    This is still a draft let me know where there is confusion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5e2f5",
   "metadata": {},
   "source": [
    "# Tutorial 07: Basic Data Files in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f195b47",
   "metadata": {},
   "source": [
    "## Overview \n",
    "- File input and output\n",
    "- - Simple text formats\n",
    "  - csv, xls\n",
    "- Accessing data\n",
    "- - Numpy array slices (data-sci/ 1-numpy)\n",
    "  - Pandas dataframe (data-sci/ 4-pandas)\n",
    "\n",
    " \n",
    "In data science, it is very common for your Python code to access a file containing the data you want to analyze. Like most programming languages, there are a variety of techniques available in Python to work with file input and output (I/O for short). \n",
    "\n",
    "Luckily, most astronomical data is saved in formats that are easier to work with once you understand the functions available. In addition to built-in functions for I/O, there are useful functions in both the NumPy and Pandas packages that we will explore in this tutorial. \n",
    "\n",
    "\n",
    "A later tutorial will work with several other common file formats including fits files. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d484ca0b-a4d7-4a43-a99f-7e694abd3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa2009-9857-4700-a640-e9035d49fa19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.0) Data file formats\n",
    "\n",
    "Before you can choose the best way to import your data file, you need to know more about the format of that data file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1a4bd-cbc2-4f4d-9905-b30e2fa28fec",
   "metadata": {},
   "source": [
    "### ascii files\n",
    "\n",
    "ASCII files are generic format files that can be read or produced by most applications. There are three common ASCII data formats: .DAT, .CSV, and .TXT. ASCII files are generic format files read or produced by most applications. These files can also be imported into most applications, including word processors, spreadsheets, and ASCII editors.\n",
    "\n",
    "Ascii files can be viewed by text editors and web browsers very easily. You will want to visually look at the file contents (at least the first few lines) to understand the data better. \n",
    "\n",
    "Things to look for:\n",
    "* Can I view the text?\n",
    "* Is there a common format on each line of the file?\n",
    "* What separates one piece of information from the next (space, comma, tab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cf52e-4972-4850-9b01-8e34017af740",
   "metadata": {},
   "source": [
    "### Spreadsheet files\n",
    "\n",
    "Add more info here...\n",
    "\n",
    ".xls and .ods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e59ac-9482-4184-95fd-ad0cd7ccf42f",
   "metadata": {},
   "source": [
    "### Other data formats\n",
    "\n",
    "In this tutorial, we note that there are many other file formats that can be used for storing data. A complete coverage of these files is beyond the scope of this tutorial. Another later tutorial in this series does cover a common astronomical data file type called a .fits file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc689c23-ab3d-4969-8fee-730b97bedaec",
   "metadata": {},
   "source": [
    "### Data Examples\n",
    "\n",
    "Throughout this tutorial, we will show specific examples of opening Data files with the various techniques. For these tutorials, all data files will be contained in a directory `data/` stored alongside the tutorial files. You will need to ensure these data files are downloaded/uploaded with the Jupyter notebooks. \n",
    "\n",
    "If you are working on a jupyter-notebook server such as Anaconda on the Cloud or the Rubin Science Platform, you should be able to view the data files in the jupyter-server. \n",
    "\n",
    "When we say `filename`, that is a string which contains both the path to the file and the name of the file. \n",
    "\n",
    "If you download the entire tutorial directory with the `data/` directory, you can reference individual files with the syntax `./data/filename`\n",
    "For example the first file we will look at is the file named \"the-zen-of-python.txt\". In that case the full filename with path would be written as \n",
    "`\"./data/the-zen-of-python.txt\"`\n",
    "\n",
    "\n",
    "<blockquote> \n",
    "    \n",
    "    **Caution**\n",
    "    \n",
    "    Depending on how you are opening this tutorial or running this code in Python, the kernel will have different rules for how you must specify the pathname for the datafile you are accessing. You may need to change the path definition in the various cells which refer to the data files you should use.\n",
    "    \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21344588-3146-461c-97e8-39da144165b1",
   "metadata": {},
   "source": [
    "## 2.0)  Unformatted text files\n",
    "\n",
    "If a file contains ascii text but there is no standard format line by line, then you will probable need to read each line of the file into string variables. \n",
    "\n",
    "Depending on what you need from the file, you may use a variety of string functions and conditional statements to extract that information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10665d-d1c5-48f0-9081-619e92d3ce64",
   "metadata": {},
   "source": [
    "### 2.1) Built-in open function\n",
    "\n",
    "Within Python, one of the built-in functions is `open()`.\n",
    "\n",
    "- The parameter you pass to the is the **filename**\n",
    "- Optionally you can specify the mode\n",
    "    - The default if you do not specify the mode is 'r' for read access\n",
    "    - Other common options are: 'w' to write to a file and 'a' to append to an existing file\n",
    "- The output is a file object (not the contents of the file)\n",
    "    - You still need to use other functions to read or write to that file\n",
    " \n",
    "The **file object** is a Python class with a variety of methods available. \n",
    "We will look at several of these to help you understand the options.\n",
    "\n",
    "As we move forward, we will use shorter versions of these calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af85951-f0f3-4f2e-811b-9a280a6d903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the line below by removing the # symbol to see the full help information on this function.\n",
    "#help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e6414c-8fdf-4f80-af0d-fe53c20d54c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jcash/GitHub/SCSU-PAARE-python-intro-tutorials\n"
     ]
    }
   ],
   "source": [
    "#Be sure to identify the location where your code is looking for the file.\n",
    "\n",
    "#This will return your directory.\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc21c78-a76c-455f-813d-76540710593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#Specifying the filename. \n",
    "filename = \"./data/the-zen-of-python.txt\"\n",
    "\n",
    "print(type(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b5e98d-b79b-4983-a301-ad2a1df366e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "#Opening a file to create a file object.\n",
    "fileobj = open(\"./data/the-zen-of-python.txt\",'r')\n",
    "print(type(fileobj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400920c4-94d8-4466-9e4b-10a0f9eb50bc",
   "metadata": {},
   "source": [
    "#### Checking a file\n",
    "\n",
    "When you first work with a data file, you may need to check to see if it is readable before moving forward. \n",
    "\n",
    "In general, you will already know what type of file you have and can skip this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7067d77b-6038-4766-bde9-a540ebe5fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Testing is a file is readable.\n",
    "print(fileobj.readable())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599fa70-3057-4229-bc44-5ae304028251",
   "metadata": {},
   "source": [
    "#### Reading the full file\n",
    "\n",
    "You can read in the full file into one big string using the `.read()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5c87a1-d830-4c3b-9932-0c52f62a4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren't special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you're Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it's a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let's do more of those!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileobj = open(filename)\n",
    "result = fileobj.read()\n",
    "print(type(result))\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d932fc-9673-4f1f-93c2-cdc6413fb5c1",
   "metadata": {},
   "source": [
    "#### Reading in the file line by line\n",
    "\n",
    "The `readlines()` method will give you a list where each item in the list is a string containing one line of the file.\n",
    "\n",
    "You can then do things with each line of the file by indexing the list and using string operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38d2707-0565-4931-b1b7-b058d786c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "fileobj = open(filename)\n",
    "lines = fileobj.readlines()\n",
    "\n",
    "print(type(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58ce0fe-1104-4334-9f43-3d14a3a3405d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows the number of lines in the file.\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b48cc3a-72d8-4aa1-85e3-ac18472078bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple is better than complex.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing out a single line by indexing.\n",
    "print(lines[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741715ee-f960-4abf-8ec4-1e7b62d08516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simple is better than complex.\\n', 'Complex is better than complicated.\\n']\n"
     ]
    }
   ],
   "source": [
    "#Print a subsection of the lines.\n",
    "print(lines[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552a95c6-7929-41ec-8960-3ee444a044f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Iterating over the list of lines to test for a substring.\n",
    "for line in lines:\n",
    "    if \"by\" in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b3ba6-4385-4735-940a-3b33a445a036",
   "metadata": {},
   "source": [
    "#### Splitting the lines into words\n",
    "\n",
    "If you needed to separate each line of the file into individual words, we can then use string splitting on the list of lines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e311bad1-6ab1-43c6-bc4e-401227a39bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Zen', 'of', 'Python,', 'by', 'Tim', 'Peters\\n'], ['\\n'], ['Beautiful', 'is', 'better', 'than', 'ugly.\\n'], ['Explicit', 'is', 'better', 'than', 'implicit.\\n']]\n"
     ]
    }
   ],
   "source": [
    "fileobj = open(filename)          #open the fileobject\n",
    "lines = fileobj.readlines()       #read the lines into a list of lines\n",
    "words = []                        #create an empty list to hold the words\n",
    "for line in lines:                #go line by line\n",
    "    words.append(line.split(' ')) # split each line at the spaces\n",
    "\n",
    "print(words[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093888c0-80f4-476e-a7de-e5dba27da273",
   "metadata": {},
   "source": [
    "**closing a file**\n",
    "\n",
    "Notice that in the above examples, we had to open the file each time. Technically we should be closing the file in between these open calls. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd89650f-3a4d-4c10-9eb6-ef7945674b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is still open\n"
     ]
    }
   ],
   "source": [
    "#check to see if a fileoject is closed\n",
    "if fileobj.closed == False:\n",
    "    print('it is still open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72aeff46-7047-4b97-824c-112f07b51f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the syntax to close a file\n",
    "fileobj = open(filename)\n",
    "lines = fileobj.readlines()\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e5a7c-1a9e-4383-9d0f-a749051da877",
   "metadata": {},
   "source": [
    "**with statements to open a file**\n",
    "\n",
    "Using a `with` statement allows python to open the file, execute a section of code and then properly close the `fileobject` without having to do an explicit `close` command. For this reason, it is often the preferred method. \n",
    "\n",
    "The syntax is a little different for the order of the command but it contains the same information in a more compact format.\n",
    "\n",
    "Since the variable for the fileobject is only used inside the with statement, it is often shortened to just `f` (just make sure you have not already used that variable name for something else).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b259ec68-79fa-4585-b8eb-f2f1e7131734",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/the-zen-of-python.txt\"\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    words =[]\n",
    "    for line in lines:\n",
    "        words.append(line.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748adab2-0bc6-47f4-83c0-7f1566f112ff",
   "metadata": {},
   "source": [
    "### 2.2) Advantages of the open function\n",
    "\n",
    "The advantage of using the built-in `open()` function in Python is that it will work for any ascii textfile. \n",
    "\n",
    "- The file can contain any number of rows of any length. \n",
    "- The length of each line doesn't matter.\n",
    "- The lines can contain any type of information\n",
    "- You can treat each line anyway you need to in order to extract any information you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80499a-43b2-4e09-b4d6-676aaec11875",
   "metadata": {},
   "source": [
    "### 2.3) DisAdvantages of the open function\n",
    "\n",
    "Although the `open()` function is very powerful, there are often more efficient ways to access the data in the file if it has a well ordered structure for the data. \n",
    "\n",
    "You do need to know your data first to use these other methods but once you do, you can use the best method from the other ones in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597e065-d137-4001-8bc8-e658c6237338",
   "metadata": {},
   "source": [
    "## 3.0) Column formatted text files \n",
    "\n",
    "If the data file contains ascii text with a standard format on each line, we have some more efficient ways to read in and work with the data.\n",
    "\n",
    "In particular, in Data Science we often have columns of data with each row containing the same number of columns. \n",
    "\n",
    "Below are examples of a few files that we will now be using. We summarize the first few lines of each files as raw text here just to give you a view of each file. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "35e20a55-b4e4-418e-86e7-e2a8a55459b4",
   "metadata": {},
   "source": [
    "#The file \"syn.txt\"\n",
    "\n",
    "0.048962338191566035 12.070034199388704\n",
    "0.47187691702469947 12.64081926075754\n",
    "0.6640550445890903 12.855809193661562\n",
    "0.8374849760923397 13.012717783375788\n",
    "1.2259257577901583 13.207036063138272\n",
    "\n",
    "\n",
    "#The file \"GCN25560.txt\"\n",
    "\n",
    "    JD           dt_minutes   ap_mag   Mag_err\n",
    "2458725.366  51.16  16.93   0.01\n",
    "2458725.372  59.80  17.21   0.02\n",
    "2458725.394  91.48  18.00   0.12\n",
    "2458725.400 100.12  18.08   0.04\n",
    "\n",
    "\n",
    "\n",
    "#The file \"galaxies.txt\"\n",
    "\n",
    "# mangaid,objra,objdec,redshift\n",
    "1,133.3711,57.598427,0.039515216\n",
    "2,133.68567,57.48025,0.041055806\n",
    "3,136.01717,57.09233,0.04657103\n",
    "4,133.98996,57.677967,0.01435065\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The file \"Moons_and_planets.csv\"\n",
    "\n",
    "# Name of Moon, Name of Planet, Diameter (km)\n",
    "Moon,Earth,1737.1\n",
    "Phobos,Mars,11.1\n",
    "Deimos,Mars,6.2\n",
    "Io,Jupiter,1818.1\n",
    "Europa,Jupiter,1560.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0917d-78c8-47a1-ae9e-21d7a8e0ee99",
   "metadata": {},
   "source": [
    "We could use the open file method described in the previous section. \n",
    "\n",
    "It will read in the lines and put the strings into a list. \n",
    "\n",
    "To use the values as numbers, we would still need to: \n",
    "- Strip off the next line character,\n",
    "- Split the lines into strings,\n",
    "- Convert each string into a number.\n",
    "\n",
    "This works as shown below (without a detailed explanation of each step), but takes a lot of code to do everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52dbead6-4e14-4b73-82a1-54637fc47b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.048962338191566035, 12.070034199388704],\n",
       " [0.47187691702469947, 12.64081926075754]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./data/syn.txt\" \n",
    "with open(filename) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data =[]\n",
    "for line in lines:\n",
    "    temp = line.rstrip('\\n')\n",
    "    vals = temp.split(' ')\n",
    "    values = []\n",
    "    for val in vals:\n",
    "        values.append(float(val))\n",
    "    data.append(values)\n",
    "    \n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21d8f8-270c-4363-91c5-525ca3c00196",
   "metadata": {},
   "source": [
    "### 3.1) Numpy loadtxt\n",
    "\n",
    "**If** the data file contains ascii text  of numbers organized into columns of data...\n",
    "\n",
    "One more efficient method you can use is the numpy function `np.loadtxt`.\n",
    "\n",
    "The general syntax is `data = np.loadtxt(filename, delimiter = None, skiprows = 0)`. \n",
    "\n",
    "If you do not specify a delimiter, it will assume whitespace.\n",
    "\n",
    "If you do not specify a number of rows to skip at the start of the file, it will start with the first line.\n",
    "\n",
    "Full documentation is given at:\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771436f-0824-43b5-bd73-446d5779e321",
   "metadata": {},
   "source": [
    "#### Files with just numbers and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59857e00-1b81-4d60-9556-a087264b3524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04896234, 12.0700342 ],\n",
       "       [ 0.47187692, 12.64081926]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is the code to read in the syn.txt file. \n",
    "filename = \"./data/syn.txt\"     #Set the path to the file.\n",
    "data = np.loadtxt(filename)     #Read in the file contents to a numpy array, no special options needed.\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26064273-ddf0-4710-b036-0985b065fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "500\n",
      "(500, 2)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#Here we can examine information about the data.\n",
    "print(type(data))\n",
    "print(len(data))\n",
    "print(np.shape(data))\n",
    "print(type(data[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41479900-0685-4638-b3a4-3dfdc191a6c2",
   "metadata": {},
   "source": [
    "As you can see above, the data is immediately accessible as a NumPy 2D data array with just a single line of code to readin the data from the file and format it as numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c25481-1461-44f1-9d0f-cd66ee008bda",
   "metadata": {},
   "source": [
    "#### Files with a header\n",
    "\n",
    "A header is a line or lines at the top of the data file containing information about the data. This information is very useful in understanding the data, but we need to be careful in how we read in the file. \n",
    "\n",
    "For `np.loadtxt` you can skip reading in these rows using the `skiprows=` parameter. \n",
    "- The default value is None\n",
    "- Otherwise, it should be an integer equal to the number of lines to skip before reading the data.\n",
    "- lines which start with the `#` symbol are considered comments and skipped automatically, but can use a skiprows parameter\n",
    "\n",
    "For our example files, \n",
    "- syn.txt had no header\n",
    "- GCN25560.txt has a single line header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b083bd2-9515-4e25-b019-82dced568b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.45872537e+06, 5.11600000e+01, 1.69300000e+01, 1.00000000e-02],\n",
       "       [2.45872537e+06, 5.98000000e+01, 1.72100000e+01, 2.00000000e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example that skips the header line.\n",
    "filename = './data/GCN25560.txt'\n",
    "data = np.loadtxt(filename,skiprows=1)\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203b51f-14fc-4861-8aff-4331570e0ee4",
   "metadata": {},
   "source": [
    "#### Files that are comma separated\n",
    "\n",
    "By default, the `np.loadtxt` assumes that the separator between the data columns in a whitespace. \n",
    "If a data file has commas seperating the values in the columns, we can still use the same method but we have to specify the delimiter.\n",
    "\n",
    "These comma-separated-values files are often given the extension of `.csv` but can also have `.txt` or `.dat` extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fecfa16a-0c17-418c-bc16-b75cf366707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.3337110e+02, 5.7598427e+01, 3.9515216e-02],\n",
       "       [2.0000000e+00, 1.3368567e+02, 5.7480250e+01, 4.1055806e-02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is a comma delimited example with one header row.\n",
    "filename = './data/galaxies.txt'\n",
    "data = np.loadtxt(filename, delimiter =',', skiprows =1)\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa12ad-21d3-4b22-9e1f-d6b391d1268e",
   "metadata": {},
   "source": [
    "### 3.2) Using Numpy if data are not all numbers\n",
    "\n",
    "NumPy is most efficient when working with numbers. Further a numpy array must have only one data type. By default, `np.loadtxt` assumes that the data can all be converted to float values. \n",
    "\n",
    "If even one value in the data file is a non numeric string, `np.loadtxt` will give an error when it tries to convert that string into a float value. \n",
    "\n",
    "We can work around this by specifically telling numpy to use a string data type when working with the file. \n",
    "\n",
    "Below, are examples of using `np.loadtxt` with the Moons_and planets.csv file\n",
    "- The first shows the correct syntax to use to get strings\n",
    "- The second cell shows the error statement you will get without the data type\n",
    "    - uncomment the command and execute to see the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99341806-f1cb-49cf-844e-c7159637442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Moon', 'Earth', '1737.1'],\n",
       "       ['Phobos', 'Mars', '11.1']], dtype='<U13')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the correct call\n",
    "file = \"./data/Moons_and_planets.csv\"\n",
    "data2 = np.loadtxt(file,dtype=\"str\",delimiter=',',skiprows=1)\n",
    "\n",
    "print(type(data2))\n",
    "data2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec824fe6-a611-4e2b-9220-84057d94489a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string 'Moon' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Moon'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/Moons_and_planets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#This will give a ValueError\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Uncomment the line below to see what the error looks like\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(file,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1017\u001b[0m         data, delimiter\u001b[38;5;241m=\u001b[39mdelimiter, comment\u001b[38;5;241m=\u001b[39mcomment, quote\u001b[38;5;241m=\u001b[39mquote,\n\u001b[1;32m   1018\u001b[0m         imaginary_unit\u001b[38;5;241m=\u001b[39mimaginary_unit,\n\u001b[1;32m   1019\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols, skiplines\u001b[38;5;241m=\u001b[39mskiplines, max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[1;32m   1020\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1021\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding, filelike\u001b[38;5;241m=\u001b[39mfilelike,\n\u001b[1;32m   1022\u001b[0m         byte_converters\u001b[38;5;241m=\u001b[39mbyte_converters)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string 'Moon' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "file = \"./data/Moons_and_planets.csv\"\n",
    "#This will give a ValueError\n",
    "#Uncomment the line below to see what the error looks like\n",
    "\n",
    "data2 = np.loadtxt(file,delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a5b22-f6c2-4eba-b631-c41022a4b437",
   "metadata": {},
   "source": [
    "Now the numpy array is an array of string values, both the words and numbers are left as strings.\n",
    "\n",
    "\n",
    "Additional information on using Numpy including a few additional functions and formats can be found at:\n",
    "\n",
    "https://numpy.org/doc/stable/user/how-to-io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a7fc2-4dfb-43ca-98b2-67f8bcbe24e0",
   "metadata": {},
   "source": [
    "### 3.3) Reading in files with Pandas\n",
    "\n",
    "Since data files may have mixed data types, numpy is not the right choice for all data files. Several other packages focus on different ways to work with Data files. **Pandas** is a very commonly used one. \n",
    "\n",
    "In their documentation they use the description: \n",
    "\n",
    "pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. Full documentation and Users guides can be found at https://pandas.pydata.org/docs/\n",
    "\n",
    "Advantages of pandas\n",
    "- It deals with multiple data types easily\n",
    "- The resulting data structure for numeric columns can be easily converted to numpy arrays\n",
    "- There are functions and methods to work with the data in the table\n",
    "- Any header information can be used to define column names (instead of just skipping the lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df814701-d2eb-49c1-a488-b45545505f08",
   "metadata": {},
   "source": [
    "#### Pandas read csv\n",
    "\n",
    "When working with data files with comma seperated values, you can use the `pd.read_csv()` function. \n",
    "\n",
    "The required parameter is the string filename, and the output is a pandas dataframe object.\n",
    "\n",
    "It is common to use df in the output variable name to indicate that it is a DataFrame, but this is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1beccd45-e193-4c1e-bf9a-ce1c8ae9e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading in the datafile\n",
    "filename = './data/galaxies.csv'\n",
    "gal_df = pd.read_csv(filename)\n",
    "\n",
    "type(gal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4dca5-a965-483d-978d-6e0589cd32f8",
   "metadata": {},
   "source": [
    "We can use the same format to look at the first few lines of the data as we did with the numpy arrays, but we immediately see that the output is easier to read. \n",
    "\n",
    "The column names were taken from the header automaticaly, and the values are shown in the normal decimal place format instead of the scientific notation format we saw in the numpy arrays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7490865-6966-4aad-87ce-b2be02b9ea5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mangaid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133.37110</td>\n",
       "      <td>57.598427</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>133.68567</td>\n",
       "      <td>57.480250</td>\n",
       "      <td>0.041056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mangaid      objra     objdec  redshift\n",
       "0          1  133.37110  57.598427  0.039515\n",
       "1          2  133.68567  57.480250  0.041056"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gal_df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337b392-247f-427e-8c3c-7cd0b4e9ff45",
   "metadata": {},
   "source": [
    "#### Pandas with other column data\n",
    "\n",
    "We can use the `pd.read_csv()` function even if the data has a different separator.\n",
    "\n",
    "You will need to specify the `delimiter` keyword or the equivalent `sep` keyword (short for separator)\n",
    "\n",
    "- A single space delimiter will use `sep=' '`\n",
    "- A variable number of white spaces will use `sep='\\s+'`\n",
    "- A comma would use `sep=','` use just leave off sep and the comma will be assumed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc628016-2199-4db9-ba8b-49202a49f7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048962</td>\n",
       "      <td>12.070034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471877</td>\n",
       "      <td>12.640819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1\n",
       "0  0.048962  12.070034\n",
       "1  0.471877  12.640819"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the syn.txt file\n",
    "#Here we set the delimiter and also say no header\n",
    "filename = './data/syn.txt'\n",
    "df = pd.read_csv(filename, sep=' ', header=None)\n",
    "\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "652148b3-b402-496a-8a03-2a9cd1a200ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JD</th>\n",
       "      <th>dt_minutes</th>\n",
       "      <th>ap_mag</th>\n",
       "      <th>Mag_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2458725.366</td>\n",
       "      <td>51.16</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2458725.372</td>\n",
       "      <td>59.80</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            JD  dt_minutes  ap_mag  Mag_err\n",
       "0  2458725.366       51.16   16.93     0.01\n",
       "1  2458725.372       59.80   17.21     0.02"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the syn.txt file\n",
    "filename = './data/GCN25560.txt'\n",
    "df = pd.read_csv(filename,sep='\\s+')\n",
    "\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f7af5-3257-4872-8970-890743bf91e6",
   "metadata": {},
   "source": [
    "#### Pandas with mixed data types\n",
    "\n",
    "While the Moons_and_planets data file was very hard to deal with using numpy, pandas has no difficulty with it at all. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d07cfbb-6663-4b2a-9a04-5c9c9371433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Name of Moon</th>\n",
       "      <th>Name of Planet</th>\n",
       "      <th>Diameter (km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moon</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1737.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phobos</td>\n",
       "      <td>Mars</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Name of Moon  Name of Planet   Diameter (km)\n",
       "0           Moon           Earth          1737.1\n",
       "1         Phobos            Mars            11.1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we see that it easily handles text and numbers\n",
    "filename = \"./data/Moons_and_planets.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29858c88-d47c-4d45-a683-66678826b269",
   "metadata": {},
   "source": [
    "## 4.0) Working with spreadsheet files\n",
    "\n",
    "While text and csv files are ascii files where the data is stored in a way that you can directly view the file, Spreadsheet programs such as Microsoft Excel or LibreOffice Calc, create files that are not ASCII. \n",
    "\n",
    "To read in the data files, we need to use different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97b7a3-a974-47fd-9ddf-9b782a479c2c",
   "metadata": {},
   "source": [
    "### 4.1) convert to csv\n",
    "\n",
    "If you only need to work with one spreadsheet file, it may be easier to open that spreadsheet with spreadsheet software and use the `Save As` options to save it out as a .csv file. Then you can use the methods described above to bring in the new .csv file into python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5be52-7046-4969-9dc0-393971028b17",
   "metadata": {},
   "source": [
    "### 4.2) Pandas and Excel\n",
    "\n",
    "Excel is commonly used enough that Pandas has a method to work with the Excel files using `pd.read_excel()` instead of `pd.read_csv()`.\n",
    "\n",
    "The function call is very similar to the `read_csv` if you only have a single sheet in the spreadsheet file. \n",
    "\n",
    "If you have multiple sheets or only need to pull in a specific range of cells from the spreadsheet, there are keyword parameters to do this. \n",
    "\n",
    "We show only the simple example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22190bd3-b3c3-4982-a75f-e2e8f99d529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mangaid</th>\n",
       "      <th>objra</th>\n",
       "      <th>objdec</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133.37110</td>\n",
       "      <td>57.598427</td>\n",
       "      <td>0.039515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>133.68567</td>\n",
       "      <td>57.480250</td>\n",
       "      <td>0.041056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mangaid      objra     objdec  redshift\n",
       "0          1  133.37110  57.598427  0.039515\n",
       "1          2  133.68567  57.480250  0.041056"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/galaxies.xlsx'\n",
    "\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac58db-3d97-4d35-8bdc-49722eac3180",
   "metadata": {},
   "source": [
    "### 4.3) Pandas and OpenDocuments\n",
    "\n",
    "The OpenDocuments format for a spreadsheet is given the extension `.ods`. \n",
    "\n",
    "LibreOffice is a cross-platform, free program that will work with `.ods` files. They can be saved out as either `.csv` or `.xlsx` files so that you can use the methods described above. \n",
    "\n",
    "Recent versions of Microsoft Excel will also read in a `.ods` file and allow you to save it in a different format. \n",
    "\n",
    "\n",
    "In the unlikely event that you need to work with these files in bulk, you will need an additional packages that are not standard in the anaconda version of python. You would need to be able to install new python packages to use these. \n",
    "\n",
    "Possible packages are:\n",
    "- `odfpy`\n",
    "- `pandas_ods_reader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a8185-75fb-4027-9626-76297dedcd9a",
   "metadata": {},
   "source": [
    "## 5.0) Writing Output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd2e6d-7057-4bf6-af77-06dc6a993040",
   "metadata": {},
   "source": [
    "### Simple ASCII text files of numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b051b-800c-4f1f-af2d-abd6380bacb6",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html#numpy.savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2affdce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename is 'outfile'.\n",
      "File isn't closed.\n"
     ]
    }
   ],
   "source": [
    "filename = \"outfile\"\n",
    "f = open(filename, 'w')\n",
    "print(\"Filename is '{}'.\".format(f.name))\n",
    "if f.closed:\n",
    "    print(\"File is closed.\")\n",
    "else:\n",
    "    print(\"File isn't closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af82ca-f05d-431f-8c22-1f109145580a",
   "metadata": {},
   "source": [
    "### Simple csv file from pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29f4b6-ea4e-46f7-b860-26ff3bc25998",
   "metadata": {},
   "source": [
    "# Assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b866aff-404a-4c81-910b-655d14fe79f2",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise, you will be working with the file 'NGC5272.txt'\n",
    "\n",
    "1) Use the built-in open method to read in the lines of the file\n",
    "    - Don't forget to close the file when done\n",
    "2) Print the first three lines of the file\n",
    "   - Use this to determine if the file has a header line\n",
    "   - Use this to determine what delimiter is used\n",
    "3) Using numpy or pandas, read in the data\n",
    "    - Print out the number of data rows\n",
    "    - Print out the first five rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f1db295-15e8-4f5c-9370-c852b379430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: use open and readlines to get the data\n",
    "\n",
    "\n",
    "# Step 2: print out the first three lines\n",
    "\n",
    "\n",
    "# Step 3: use either numpy or pandas to read the data\n",
    "\n",
    "\n",
    "# Step 3b: print out the number of rows of data\n",
    "\n",
    "\n",
    "# Step 3c: print out the first five rows of data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62952e88-f8fe-48ca-a8b8-1899b88c4df4",
   "metadata": {},
   "source": [
    "## Exercise 2  \n",
    "\n",
    "1) Read in the `Moons_and_planets.dat` file\n",
    "2) Count the number of moons for each planet above a threshold size of 100 km\n",
    "    - use one of the solutions from the earlier tutorial on conditionals and control files as a guide\n",
    "    - convert the diameters from strings into floats\n",
    "    - use the diameters to limit what moons you count\n",
    "3) Print out a statement for each planet with the name of the planet and the number of large moons it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b6bc8b-3973-47ea-889f-c06ddc166ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: read in the data file\n",
    "\n",
    "\n",
    "# Step 2a: Set up a loop to check the rows\n",
    "\n",
    "\n",
    "# Step 2b: Loop over the moons and add to each counter when you find a large moon\n",
    "\n",
    "\n",
    "# Step 3: Print out a statement for each planet with the planet and the count\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
